{
    "data": {
      "train_list": "train_clips.txt",
      "val_list": "val_clips.txt",
      "test_list": "test_list.txt",
      "sequence_length": 1,
      "shuffle": false,
      "persistent_workers": false,
      "batch_size": 5,
      "num_workers": 20,
      "camera_ids": [
        3,
        1,
        2,
        4,
        5,
        6,
        7
      ],
      "camera_groups": [
        {
          "name": "front_stereo_camera",
          "camera_group": [
            1,
            2
          ],
          "image_size": [
            576,
            288
          ],
          "normalize_mean": [
            0.485,
            0.456,
            0.406
          ],
          "normalize_std": [
            0.229,
            0.224,
            0.225
          ],
          "backbone": "repvgg_a1",
          "out_channels": 256,
          "fpn_channels": 256,
          "downsample_scale": 4,
          "use_pretrained": true
        },
        {
          "name": "short_focal_length_camera",
          "camera_group": [
            4,
            5,
            3
          ],
          "image_size": [
            400,
            256
          ],
          "normalize_mean": [
            0.485,
            0.456,
            0.406
          ],
          "normalize_std": [
            0.229,
            0.224,
            0.225
          ],
          "backbone": "repvgg_a1",
          "out_channels": 256,
          "fpn_channels": 256,
          "downsample_scale": 16,
          "use_pretrained": true
        },
        {
          "name": "rear_camera",
          "camera_group": [
            6,
            7
          ],
          "image_size": [
            576,
            288
          ],
          "normalize_mean": [
            0.485,
            0.456,
            0.406
          ],
          "normalize_std": [
            0.229,
            0.224,
            0.225
          ],
          "backbone": "repvgg_a1",
          "out_channels": 256,
          "fpn_channels": 256,
          "downsample_scale": 8,
          "use_pretrained": true
        }
      ]
    },
    "model": {
      "decoder": {
        "num_layers": 1,
        "num_queries": 64,
        "query_dim": 128,
        "feature_dim": 256,
        "hidden_dim": 512,
        "num_points": 25,
        "anchor_encoder_config": {
          "position_embedding_dim": 128,
          "dimension_embedding_dim": 32,
          "velocity_embedding_dim": 64,
          "yaw_embedding_dim": 64,
          "anchor_embedding_dim": 256,
          "anchor_generator_config": {
            "front_type": "div_x",
            "back_type": "div_x",
            "front_params": {"alpha": 0.4, "beta": 10.0, "order": 3},
            "back_params": {"alpha": 0.35, "beta": 10.0, "order": 3},
            "front_min_spacing": 4.0,
            "front_max_distance": 200.0,
            "back_min_spacing": 4.0,
            "back_max_distance": 100.0,
            "left_y_max": 7.5,
            "right_y_max": 7.5,
            "y_interval": 3.75
          }
        }
      },
      "memory_efficient": 1
    },
    "training": {
      "train_list": "train_clips.txt",
      "val_list": "val_clips.txt",
      "batch_size": 1,
      "num_workers": 20,
      "max_epochs": 100,
      "accelerator": "gpu",
      "devices": 1,
      "precision": 32,
      "accumulate_grad_batches": 1,
      "seed": 10,
      "pretrained_weights": "true",
      "limit_val_batches": 1,
      "limit_train_batches": 1,
      "learning_rate": 0.03,
      "pct_start": 0.15,
      "div_factor": 10.0,
      "final_div_factor": 1000.0,
      "weight_decay": 0.00001,
      "gradient_clip_val": 5.0,
      "use_checkpoint": true,
      "log_every_n_steps": 30,
      "check_val_every_n_epoch": 10,
      "num_sanity_val_steps": 0,
      "resume": false,
      "lr_scheduler": "one_cycle"
    },
    "predict": {
      "test_list": "test_list.txt",
      "confidence_threshold": 0.5,
      "batch_size": 1,
      "num_workers": 4,
      "accelerator": "gpu",
      "devices": 1,
      "precision": "16-mixed",
      "output_dir": "predict_results",
      "seed": 42,
      "checkpoint": "checkpoints/last.ckpt",
      "limit_batch_size": 1
    },
    "logging": {
      "log_dir": "logs/e2e_perception",
      "checkpoint_dir": "checkpoints/e2e_perception",
      "save_top_k": 3,
      "last_checkpoint_dir": "/home/xinjian/Code/pytorch-lightning/examples/pytorch/e2evision",
      "use_tensorboard": "true",
      "use_csv": "false",
      "use_wandb": "true",
      "wandb_project": "e2e_perception",
      "run_id": 0,
      "clean_wandb_history": 1,
      "progress_bar_metrics": [
        "v_num",
        "train/loss_step",
        "train/loss_epoch",
        "train/layer_3_loss_cls_epoch",
        "train/layer_3_loss_pos_epoch",
        "val/loss",
        "epoch",
        "step"
      ],
      "use_optional_metrics": "false",
      "wandb_log_metrics": [
        "train/loss_epoch",
        "val/loss",
        "train/layer_3_loss_pos_epoch",
        "train/layer_3_loss_dim_epoch",
        "train/layer_3_loss_vel_epoch",
        "train/layer_3_loss_yaw_epoch",
        "train/layer_3_loss_acc_epoch",
        "train/layer_3_loss_cls_epoch",
        "train/layer_3_fp_loss_exist_epoch",
        "train/layer_2_loss_cls_epoch",
        "train/layer_2_loss_pos_epoch",
        "train/layer_2_loss_dim_epoch",
        "train/layer_2_loss_vel_epoch",
        "train/layer_2_loss_yaw_epoch",
        "train/layer_2_loss_acc_epoch",
        "train/layer_2_loss_cls_epoch",
        "train/layer_2_fp_loss_exist_epoch",
        "train/layer_1_loss_cls_epoch",
        "train/layer_1_loss_pos_epoch",
        "train/layer_1_loss_dim_epoch",
        "train/layer_1_loss_vel_epoch",
        "train/layer_1_loss_yaw_epoch",
        "train/layer_1_loss_acc_epoch",
        "train/layer_1_loss_cls_epoch",
        "train/layer_1_fp_loss_exist_epoch"
      ],
      "with_checkpoint_copy_callback": false,
      "visualize_intermediate_results": true,
      "visualize_intermediate_results_dir": "visualize_intermediate_results",
      "point_radius": 1
    },
    "loss": {
      "weight_dict": {
        "loss_pos": 1.0,
        "loss_dim": 1.0,
        "loss_vel": 0.5,
        "loss_yaw": 0.5,
        "loss_acc": 0.1,
        "loss_cls": 1.0,
        "fp_loss_exist": 2.0
      },
      "layer_loss_weights": [
        0.1,
        0.3,
        0.5,
        0.7,
        0.8,
        0.9,
        1.0
      ],
      "frames": 10,
      "dt": 0.1,
      "iou_method": "iou2",
      "iou_threshold": 0.5
    },
    "validate_only": 0
  }